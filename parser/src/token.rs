use crate::internal::*;

#[derive(Debug, PartialEq, Eq, Clone, Copy, Default)]
pub enum TokenKind {
  Ampersand,
  Backtick,
  Backslash,
  Bang,
  CalloutNumber,
  Caret,
  CloseBrace,
  CloseBracket,
  Colon,
  Comma,
  Dashes,
  DelimiterLine,
  Digits,
  Directive,
  Discard,
  DoubleQuote,
  Dots,
  EqualSigns,
  #[default]
  Eof,
  ForwardSlashes,
  GreaterThan,
  Hash,
  LessThan,
  MacroName,
  MaybeEmail,
  Newline,
  OpenBrace,
  OpenBracket,
  Percent,
  Pipe,
  Plus,
  SemiColon,
  SingleQuote,
  Star,
  TermDelimiter,
  Tilde,
  Underscore,
  Whitespace,
  Word,
}

#[derive(Clone, PartialEq, Eq)]
pub struct Token<'src> {
  pub kind: TokenKind,
  pub loc: SourceLocation,
  pub lexeme: BumpString<'src>,
}

impl<'src> Token<'src> {
  // pub fn to_string<'bmp>(&self, bump: &'bmp Bump) -> BumpString<'bmp> {
  //   BumpString::from_str_in(self.lexeme, bump)
  // }

  pub fn to_source_string<'bmp>(&self, bump: &'bmp Bump) -> SourceString<'bmp> {
    // let bump_str = BumpString::from_str_in(self.lexeme, bump);
    SourceString::new(self.lexeme, self.loc)
  }

  pub fn to_url_scheme(&self) -> Option<UrlScheme> {
    match self.kind {
      TokenKind::MacroName => match self.lexeme.as_str() {
        "https:" => Some(UrlScheme::Https),
        "http:" => Some(UrlScheme::Http),
        "ftp:" => Some(UrlScheme::Ftp),
        "irc:" => Some(UrlScheme::Irc),
        "mailto:" => Some(UrlScheme::Mailto),
        _ => None,
      },
      _ => None,
    }
  }

  pub const fn len(&self) -> usize {
    self.lexeme.len()
  }

  pub fn parse_callout_num(&self) -> Option<u8> {
    let ascii_digits = self
      .lexeme
      .bytes()
      .filter(u8::is_ascii_digit)
      .collect::<SmallVec<[u8; 3]>>();
    if ascii_digits.is_empty() {
      None // autogenerated: <.>
    } else {
      // SAFETY: we only have ascii digits, so this is fine
      let num_str = unsafe { std::str::from_utf8_unchecked(&ascii_digits) };
      // maybe better warn than expect?
      Some(num_str.parse::<u8>().expect("exceeded max 255 callouts"))
    }
  }

  pub fn drop_leading_bytes(&mut self, n: usize) {
    debug_assert!(n <= self.lexeme.len());
    self.kind = TokenKind::Word;
    if n > 0 {
      self.lexeme = &self.lexeme[n..];
      self.loc.start += n;
    }
  }
}

pub trait TokenIs {
  fn is_url_scheme(&self) -> bool;
  fn is(&self, kind: TokenKind) -> bool;
  fn is_len(&self, kind: TokenKind, len: usize) -> bool;
  fn is_not(&self, kind: TokenKind) -> bool {
    !self.is(kind)
  }
  fn is_not_len(&self, kind: TokenKind, len: usize) -> bool {
    !self.is_len(kind, len)
  }
  fn is_whitespaceish(&self) -> bool {
    self.is(TokenKind::Whitespace) || self.is(TokenKind::Newline)
  }
}

impl<'src> TokenIs for Token<'src> {
  fn is(&self, kind: TokenKind) -> bool {
    self.kind == kind
  }

  fn is_len(&self, kind: TokenKind, len: usize) -> bool {
    self.kind == kind && self.len() == len
  }

  fn is_url_scheme(&self) -> bool {
    self.to_url_scheme().is_some()
  }
}

impl<'src> TokenIs for Option<&Token<'src>> {
  fn is(&self, kind: TokenKind) -> bool {
    self.map_or(false, |t| t.is(kind))
  }

  fn is_len(&self, kind: TokenKind, len: usize) -> bool {
    self.map_or(false, |t| t.is_len(kind, len))
  }

  fn is_url_scheme(&self) -> bool {
    self.map_or(false, |t| t.is_url_scheme())
  }
}

impl<'src> std::fmt::Debug for Token<'src> {
  fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
    write!(
      f,
      "Token {{ {:?}, \"{}\", {:?} }}",
      self.kind, self.lexeme, self.loc
    )
  }
}
